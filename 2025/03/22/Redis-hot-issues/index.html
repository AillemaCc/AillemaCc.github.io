<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Redis-hot-issues | AllimacBlog</title><meta name="author" content="Allimac"><meta name="copyright" content="Allimac"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Redis为什么这么快 redis 官方早前发布过一套基准测试，在 Redis 服务连接数小于 1 万时，并发数量每秒可以达到 10-12 万左右。连接数在 3-6 万 时，也能支持每秒 5-6 万的并发。 我觉得 Redis 之所以操作这么快，主要有以下几方面原因：  从存储方式上看：Redis 是基于内存的数据库，而直接访问内存的速度要比访问磁盘高上几个数量级。这是 Redis 快最主要的原因">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis-hot-issues">
<meta property="og:url" content="http://example.com/2025/03/22/Redis-hot-issues/index.html">
<meta property="og:site_name" content="AllimacBlog">
<meta property="og:description" content="Redis为什么这么快 redis 官方早前发布过一套基准测试，在 Redis 服务连接数小于 1 万时，并发数量每秒可以达到 10-12 万左右。连接数在 3-6 万 时，也能支持每秒 5-6 万的并发。 我觉得 Redis 之所以操作这么快，主要有以下几方面原因：  从存储方式上看：Redis 是基于内存的数据库，而直接访问内存的速度要比访问磁盘高上几个数量级。这是 Redis 快最主要的原因">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.png">
<meta property="article:published_time" content="2025-03-22T10:19:32.000Z">
<meta property="article:modified_time" content="2025-03-22T10:21:34.292Z">
<meta property="article:author" content="Allimac">
<meta property="article:tag" content="八股">
<meta property="article:tag" content="Redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Redis-hot-issues",
  "url": "http://example.com/2025/03/22/Redis-hot-issues/",
  "image": "http://example.com/img/avatar.png",
  "datePublished": "2025-03-22T10:19:32.000Z",
  "dateModified": "2025-03-22T10:21:34.292Z",
  "author": [
    {
      "@type": "Person",
      "name": "Allimac",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/faviconcute.png"><link rel="canonical" href="http://example.com/2025/03/22/Redis-hot-issues/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Redis-hot-issues',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">49</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">44</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/nature_top_image.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">AllimacBlog</span></a><a class="nav-page-title" href="/"><span class="site-name">Redis-hot-issues</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Redis-hot-issues</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-22T10:19:32.000Z" title="发表于 2025-03-22 18:19:32">2025-03-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-22T10:21:34.292Z" title="更新于 2025-03-22 18:21:34">2025-03-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">9.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>31分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a>Redis为什么这么快</h1><p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEdEYhF"><img src="https://s21.ax1x.com/2025/03/17/pEdEYhF.png" alt="pEdEYhF.png"></a></p>
<p>redis 官方早前发布过一套基准测试，<strong>在 Redis 服务连接数小于 1 万时，并发数量每秒可以达到 10-12 万左右</strong>。连接数在 3-6 万 时，也能支持每秒 5-6 万的并发。</p>
<p>我觉得 Redis 之所以操作这么快，主要有以下几方面原因：</p>
<ul>
<li><strong>从存储方式上看</strong>：Redis 是基于内存的数据库，而直接访问内存的速度要比访问磁盘高上几个数量级。这是 Redis 快最主要的原因。</li>
<li><strong>从设计上看</strong>：Redis 在架构上采用了 IO 多路复用提高了资源利用率，通过多线程非阻塞式 IO 提高请求的处理效率  ，使用单线程执行大部分命令以避免上下文切换，部分重命令则允许异步执行，并且在设计上针对最底层的数据结构进行了精细的优化，以保证任何操作都具备尽可能低的复杂度。</li>
<li><strong>从使用方式上看</strong>：Redis 的功能非常纯粹，用户直接面向经过精心设计的数据结构进行操作，因此效率极高，此外，用户还可以根据自己的业务场景采用最合适的数据结构，这也间接提高了操作效率。</li>
</ul>
<h2 id="基于内存操作"><a href="#基于内存操作" class="headerlink" title="基于内存操作"></a>基于内存操作</h2><p>Redis 是<strong>基于内存操作的数据库</strong>，这是它快的最根本原因。</p>
<p>一般情况下，计算机访问一次 SSD 硬盘大概需要 50 ~ 150 微秒，如果是传统的硬盘时间则需要 1 ~ 10 毫秒，而访问一次内存仅需要 120 纳秒。可见，磁盘和内存访问的速度差了数个数量级。</p>
<p>除了少数一些需要需要跟磁盘打交道的时候（比如持久化），大部分时候 Redis 都只在内存中进行读写，因此它的效率极高。</p>
<h2 id="合理的线程模型"><a href="#合理的线程模型" class="headerlink" title="合理的线程模型"></a>合理的线程模型</h2><p>我们一般说“Redis”是单线程的，实际上是指 Redis 使用单个主线程来执行大部分的命令。这个设计使得 Redis 可以避免因频繁的上下文切换以及各种同步机制带来的性能开销，同上也避免的了为了保证数据结构支持并发操作而引入的代码复杂度。</p>
<p>不过，Redis 也并非真的就是单线程的，从 4.0 开始，Redis 就引入了 <code>UNLINK</code> 这类命令，用于异步执行删除等重操作，并在 6.0 以后引入了专门的 IO 线程，实现了多线程的非阻塞式 IO，它们也进一步的提升了 Redis 的执行效率。</p>
<blockquote>
<p>这里我们要顺带强调一下，<strong>虽然 Redis 的单个主线程模型确实带来的不少的好处，但是这个设计更多的还是在性能与设计之间取得的一个平衡</strong>。实际上不少市面上开源或者大公司内部自研的 KV 数据库 —— 比如 KeyDB 或者  Dragonfly —— 都是基于多线程模型实现的，它们以单机模式运行在多核机器上时也确实表现出了比 Redis 更高的性能。</p>
</blockquote>
<h2 id="高效IO模型"><a href="#高效IO模型" class="headerlink" title="高效IO模型"></a>高效IO模型</h2><h3 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h3><p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEdE21H"><img src="https://s21.ax1x.com/2025/03/17/pEdE21H.png" alt="pEdE21H.png"></a></p>
<p>为了提高资源利用率，提高服务吞吐量，Redis 在内部实现了一套网络事件库，它支持基于 Solaris 中的 evport、Linux 中的 epoll、Mac OS&#x2F;FreeBSD 中的 kQueue ……等操作系统函数实现高效的 IO 多路复用。</p>
<p>在这个模型中，它将会来自客户端的网络请求作为一个事件发布到队列中，然后线程将同步的获取事件并派发到不同的处理器，而处理器处理完毕后又会再发布另一个事件……整个主流程都由 Redis 的主线程在一个不间断的循环中完成，这就是事件循环。</p>
<p>熟悉 Netty 的同学可能会觉得有点既视感，因为两者都可以认为基于反应器模式实现的 IO 模型，不过 Netty  可以有多个事件循环，并且还可以划分为 Boss 和 Worker 两类事件循环组，而 Redis 只有一个事件循环，并且在早期版本只有一个 IO 线程（也就是主线程本身）。</p>
<h3 id="多线程非阻塞IO"><a href="#多线程非阻塞IO" class="headerlink" title="多线程非阻塞IO"></a>多线程非阻塞IO</h3><p>随着请求规模的扩大，单个线程在网络 IO 上消耗的 CPU 时间越来越多，它逐渐成为了 Redis 的性能瓶颈。因此在 6.0 版及以上版本，Redis 正式引入了多线程来处理网络 IO。</p>
<p>在新的版本中，Redis 依然使用单个主线程来执行命令，但是使用多个线程来处理 IO 请求，主线程不再负责包括建立连接、读取数据和回写数据这些事情，而只是专注于执行命令。</p>
<p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEdEhnI"><img src="https://s21.ax1x.com/2025/03/17/pEdEhnI.png" alt="pEdEhnI.png"></a></p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>Redis 的高性能很大程度上依赖于它丰富而高效的数据结构，而它们<strong>在底层实现上，都针对不同的使用场景进行了精心的设计和优化</strong>。</p>
<p>这些设计体现在这些数据结构的很多方面，这里我们简单列举几个 Redis 自己都在使用的数据结构。</p>
<h3 id="简单动态字符串"><a href="#简单动态字符串" class="headerlink" title="简单动态字符串"></a>简单动态字符串</h3><p>SDS 的特点是在保留 C 字符串特性的同时：</p>
<ul>
<li><strong>通过 len 记录了字符串长度</strong>：实现了 O(1) 复杂度的 <code>strlen</code> 操作，并保证了二进制安全性。</li>
<li><strong>通过 alloc 记录了分配的内存大小</strong> ：这使得修改字符串的时候可以通过计算，仅当空间不足时再扩展。</li>
<li><strong>通过 flags 表示不同的类型</strong>：Redis 在内部针对区分了多种 SDS 类型，不同大小的字符串会对应不同的 SDS 实现，有效的节省内存。</li>
</ul>
<p>可见，除了优化了内存占用外，Redis 的 SDS 也从最底层优化了包括内存分配和长度获取等基本操作，提升了性能。</p>
<h3 id="字典-哈希表"><a href="#字典-哈希表" class="headerlink" title="字典&#x2F;哈希表"></a>字典&#x2F;哈希表</h3><p>Redis 的哈希表与 Java 中相似，也是<strong>基于 Key 得到的哈希值计算桶下标，再采用拉链法解决冲突，并在装载因子超过预定值时自动扩容</strong>。</p>
<p>它的特殊之处在于，当扩容的时候，它会<strong>基于扩容后的大小创建一张新的哈希表</strong>，然后在访问旧表的时候，每次将访问到的桶中的链表转移到新表中。</p>
<p>在这个过程中，每次操作的时候都会先访问旧表，然后再访问新表，<strong>直到旧表的数据组件的全部转移到新表以后</strong>，旧表会被回收，只留下新表。</p>
<p>Redis 通过这个被称为渐进式哈希的设计，<strong>巧妙地避免的在一次操作中大批量的进行数据迁移，而是将其分摊到多次请求中</strong>，这也有效提高的了该数据结构的使用性能。</p>
<h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p>每个元素在不同层次的链表中出现，从最底层链表开始，每个级别的链表包含前一个级别链表的子集。当我们进行查找时，可以从最高层的 k 索引开始遍历，当我们确认一个元素大于 k 层的某个节点时，就进入 k-1 层，从这个节点开始继续向前遍历……直到找到为止。</p>
<p><strong>相比起正常的列表，它在插入、删除和搜索时都具备 O(logN) 的复杂度，并且相比起树实现起来更加简单</strong>。</p>
<h1 id="如何实现到期删除"><a href="#如何实现到期删除" class="headerlink" title="如何实现到期删除"></a>如何实现到期删除</h1><p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEdVtVP"><img src="https://s21.ax1x.com/2025/03/17/pEdVtVP.png" alt="pEdVtVP.png"></a></p>
<p>在 Redis 中，我们可以用 <code>EXPIRE</code>、<code>PEXPIRE</code>、<code>EXPIREAT</code> 和 <code>PEXPIREAT</code>四个命令来按毫秒或秒设置 Key 的过期时间。其中，前两者指定的是 Key 的有效时间，而后两者指定的是 Key 的到期时间点。</p>
<p>这些时间最终会被转换为一个时间戳并，与 Key 一一对应保存在一个到期字典中，然后 Redis 会根据 Key 在到期字典中的到期时间，通过主动和被动两种方式清理到期的 Key。</p>
<p><strong>被动删除</strong>是指每次访问 Key 键时，Redis 会检查 Key 是否已到期，如果是就将其删除并返回空值。不过如果仅靠被动删除是不够的，因为如果 Key 的访问频率不高，可能会导致一些数据一直不能被删除，内存也无法得到释放，因此所以还需要定期的主动删除。</p>
<p><strong>主动删除</strong>是指 Redis 会每秒主动扫描 10 次到期字典，随机抽取 20 个 Key 并删除其中已经到期的部分。然后，如果这次抽样中到期键的 Key 的比例超过 25%，就会继续抽样，直到不满足条件或超时为止。</p>
<p>以上两种删除机制互相配合，基本能保证 Redis 中到期键的数量不会超过总数据量的 25%。</p>
<p>另外，Redis 在持久化的时候也会针对到期的 Key 做额外的处理。Redis  在 AOF 的时候，如果 Key 过期了，则会向文件追加一条 <code>DEL</code> 指令，而如果是在 AOF 重写和 RDB 的时候，则检查并直接忽略掉过期的 Key。</p>
<p>最后是集群，在集群里面，当主节点发现 Key 到期时，会向所有从节点发送 <code>DEL</code> 命令，但是当从节点发现键到期时，只会将其标记为已删除，直到收到主节点的删除指令才会真正删除，以确保数据一致性。</p>
<h2 id="到期时间"><a href="#到期时间" class="headerlink" title="到期时间"></a>到期时间</h2><p>在 Redis 中，你可以使用以下四种命令为 Key 设置到期时间：</p>
<ul>
<li><code>EXPIRE</code>：以<strong>秒</strong>为单位，设置 Key 的有效时间。</li>
<li><code>PEXPIRE</code>：以<strong>毫秒</strong>为单位，设置 Key 的有效时间。</li>
<li><code>EXPIREAT</code>：以<strong>秒</strong>为单位，设置 Key 的到期时间戳。</li>
<li><code>PEXPIREAT</code>：以<strong>毫秒</strong>为单位，设置 Key 的到期时间戳。</li>
</ul>
<p>其中，前两者指定的是 Key 的<strong>有效时长</strong>，而后两者指定的是 Key <strong>到期时间点</strong>。</p>
<p>不过，在 Redis 底层实现中，四种命令最终都会变为 Key 到期时间点对应的时间戳，并被记录在一个到期字典中（哈希表）。</p>
<h2 id="删除策略"><a href="#删除策略" class="headerlink" title="删除策略"></a>删除策略</h2><p>按官方文档的说法，Redis 的过期删除有<strong>两种方式</strong>：</p>
<ul>
<li><strong>主动删除</strong>：每 10 秒扫描一次数据库，随机抽 20 个 key，并删除其中到期的 key。如果到期 Key 占比超过 25%，那么继续抽样，直到不满足条件或超时为止；</li>
<li><strong>被动删除</strong>：访问 Key 时检查到期时间，如果已经到期就删除；</li>
</ul>
<p>官方文档对此进行了解释：<a target="_blank" rel="noopener" href="https://redis.io/commands/expire/">Redis 官网 – EXPIRE 指令介绍</a></p>
<h3 id="定时删除"><a href="#定时删除" class="headerlink" title="定时删除"></a>定时删除</h3><p>这里我们顺便提一下一个 Redis 没有使用，而非常简单粗暴的思路，那就是定时删除。</p>
<p>简单的来说，就是在设置 Key 的到期时间时，一并设置一个定时事件，等到事件触发时删除 key。</p>
<ul>
<li>优点： 可以及时释放资源，确保过期键能够被及时删除。</li>
<li>缺点： 频繁的删除操作可能会占用大量的 CPU 时间。</li>
</ul>
<p>总的来说，这个策略对内存优化而对 CPU 不友好，在 CPU 紧张而内存宽裕的场景中，它会将更多的 CPU 资源花费到没那么紧要的删除到期 Key 操作上。</p>
<p>综合上述考量， <strong>Redis 并没有使用这种方式</strong>。</p>
<h3 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h3><p><strong>惰性删除就是 Redis 提到的被动删除。</strong></p>
<p>被动删除不会主动的删除到期的 key，而是当访问 Key 时再检查是否到期，如果到期了再将其删除。</p>
<p>它的优缺点与定时删除刚好相反：</p>
<ul>
<li>优点： 只在取出键时进行检查，避免了频繁的删除操作。</li>
<li>缺点： 可能会导致内存积压问题。</li>
</ul>
<p>惰性删除对 CPU 最友好，但是对内存就不友好了。尤其是当你需要在 Redis 中存放大量具备到期时间且不需要频繁访问的数据时，会造成内存积压。</p>
<h3 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h3><p>具体来说，整个过程如下：</p>
<ol>
<li>Redis 定时（取决于 hz配置，默认为 10，即每秒 10 次）依次遍历 16 个数据库：<ol>
<li>如果此时到期字典可用率较低，考虑到哈希冲突严重时链表可能很长，遍历需要额外的时间成本，那么将会直接跳过该数据库，等到下一次循环其重哈希以后再进行处理。</li>
<li>如果字典可用率处于正常水平，那么就依次从数据库的到期字典中对 Key 进行抽样（<strong>20 个</strong>），并删除已超时的 Key；</li>
</ol>
</li>
<li>如果此次抽样中，到期 Key 的占比高于一定阈值（<strong>25%</strong>），则会再进行一次抽样删除，直到到期 Key 占比没那么高。或者本次任务执行超时为止；</li>
<li>如果此次执行超时了，那么将会记录当前处理的数据库下标，然后下次进行抽样时就直接从当前数据库开始执行，如此反复。</li>
</ol>
<p>相对于定时删除和惰性删除，定期删除<strong>在内存和 CPU 消耗中取得了一个比较好的平衡</strong>。</p>
<p>另外，使用抽样避免全量操作的思想在 Redis 中挺常见的，比如内存淘汰策略中的近似 LRU 和 LFU</p>
<h4 id="为什么要抽样而不是全量检查"><a href="#为什么要抽样而不是全量检查" class="headerlink" title="为什么要抽样而不是全量检查"></a>为什么要抽样而不是全量检查</h4><p>每次大批量的筛选并删除 Key 是十分消耗性能的，并且长时间的阻塞 Redis 的主线程还会降低吞吐量。为了避免上述的问题，Redis 需要通过控制筛选范围降低 Key 的数量，从而来提高操作性能并降低阻塞的时间。</p>
<p>当然，即便如此，如果你为大量的 Key 设置了接近的超时时间，那么当它们同时失效 —— 我们一般称呼这种常见为缓存雪崩 —— 时，由于每次抽样中到期 Key 占比都会高于  25% 的概率极高，那么 Redis 依然不得不花费更多的时间来删除大量的  Key。虽然有一个整体超时时间来兜底，但是为了提高效率，还是最好通过设置不同的超时时间之类的操作尽可能避免这种情况。</p>
<h4 id="如何控制定期删除的触发频率"><a href="#如何控制定期删除的触发频率" class="headerlink" title="如何控制定期删除的触发频率"></a>如何控制定期删除的触发频率</h4><p>一般来说，我们可以通过配置文件中的hz参数来指定定期删除任务的触发频率，它默认为 10，即每 1s 执行 10 次，最大可以调成 500。</p>
<p>需要注意的是，这个参数实际上不止用于控制定期删除的执行频率，redis 中几乎所有定期执行的后台任务都通过该值来设置 ——  比如关闭超时的客户端连接，或者更新统计信息之类的 —— 因此，调大这个值会导致 Redis 服务占用更多的 CPU 资源。不过，如果你的  Redis 服务会有大量的 ttl 极短的 Key，那么你可以适量的调大 <code>hz</code>参数来及时清理掉这些朝生夕死的 Key。</p>
<p>总而言之，这是又是一个 <strong>CPU 和内存占用的权衡问题</strong>，不过 Redis 也提供了 <code>dynamic-hz</code> 的配置，当你设置为 yes 的时候，Redis 会根据情况适当的根据 <code>hz</code> 调整实际的触发频率，这个配置默认都是开启的。</p>
<p>这里我们直接放上配置文件，你可以结合注释来感受一下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># Redis调用一个内部函数来执行许多后台任务，比如</span><br><span class="line"># 关闭超时的客户端连接，清理从未被请求的过期键等等。</span><br><span class="line">#</span><br><span class="line"># 并非所有任务的执行频率都相同，但Redis根据指定的“hz”值检查要执行的任务。</span><br><span class="line">#</span><br><span class="line"># 默认情况下，“hz”设置为10。增加这个值会在Redis空闲时使用更多CPU资源，</span><br><span class="line"># 但同时会使得Redis在有许多键同时过期时响应更快，并且超时处理可能会更精确。</span><br><span class="line">#</span><br><span class="line"># 可选值范围在1到500之间，但通常超过100不是一个好主意。大多数用户应该使用默认值10，</span><br><span class="line"># 在需要非常低延迟的环境中可以将其提高到100。</span><br><span class="line"></span><br><span class="line">hz 10</span><br><span class="line"></span><br><span class="line"># 通常情况下，拥有与连接客户端数量成比例的HZ值是有用的。</span><br><span class="line"># 例如，这对于避免在每次后台任务调用中处理过多客户端以避免延迟峰值很有用。</span><br><span class="line">#</span><br><span class="line"># 由于默认情况下HZ值保守地设置为10，Redis提供并默认启用了使用自适应HZ值的能力，</span><br><span class="line"># 当有许多连接的客户端时会临时提高HZ值。</span><br><span class="line">#</span><br><span class="line"># 启用动态HZ时，实际配置的HZ将作为基线使用，但一旦连接更多客户端，</span><br><span class="line"># 将根据需要使用配置的HZ值的倍数。这样，空闲实例将使用非常少的CPU时间，而繁忙实例将更具响应性。</span><br><span class="line"></span><br><span class="line">dynamic-hz yes</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="在持久化时"><a href="#在持久化时" class="headerlink" title="在持久化时"></a>在持久化时</h2><p>Redis 使用 AOF 与 RBD 两种方式来持久化内存中数据，这个过程同样需要考虑如何处理过期的 key：</p>
<ul>
<li>AOF：当 Key 因为到期而被删除时，将会向 AOF <strong>追加一条</strong> <code>DEL</code> <strong>命令</strong>。如果在这个过程中进行了 AOF 重写，那么重写后的 AOF 文件中则将<strong>直接忽略掉</strong>这个过期的 Key。</li>
<li>RDB：与 AOF 重写类似，在创建 RDB 的时候，过期的 Key 会被<strong>直接忽略</strong>。</li>
</ul>
<h2 id="在集群中"><a href="#在集群中" class="headerlink" title="在集群中"></a>在集群中</h2><p>当集群中的实例发现 Key 到期后，实例会根据它自己是主节点还是从节点而采取不同的行为：</p>
<ul>
<li>如果是<strong>主节点</strong>，它会在删除这个过期 Key 后向所有从节点发送一个 <code>DEL</code> 命令。</li>
<li>如果是<strong>从节点</strong>，那么它将会将这个 Key 标记为到期，但并不会真正的删除。只有当接到从主节点发来的 <code>DEL</code> 命令之后，才会真正的将过期键删除掉。</li>
</ul>
<p>从节点不会主动删除 key，这是为了保证与主节点数据的一致性，以便当主从切换时后，仍然可以正常的处理过期 key。</p>
<p>不过当系统中有大量频繁过期的 key，且一个主节点有较多从节点的时候，这会带来更多的内存消耗。</p>
<blockquote>
<p>关于主从集群中到期时间的处理，可以参照官方文档 <a target="_blank" rel="noopener" href="https://redis.io/docs/management/replication/#how-redis-replication-deals-with-expires-on-keys">Redis replication sourl.cn&#x2F;HRJygR</a> 这部分内容。</p>
<p>不过在文档中似乎并没有明确指出缺少这种“延迟删除”的措施会导致怎样的后果，只说是为了不违反数据一致性 （don’t violate the consistency of the data set）。</p>
</blockquote>
<h1 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h1><p>从淘汰范围来说可以分为不淘汰任何数据、只从设置了到期时间的键中淘汰和从所有键中淘汰三类。而从淘汰算法来分，又主要分为 Random（随机），LRU（最近最少使用），以及 LFU（最近最不常使用）三种。</p>
<p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEdZnLn"><img src="https://s21.ax1x.com/2025/03/17/pEdZnLn.png" alt="pEdZnLn.png"></a></p>
<p>内存总是有限的，因此当 Redis 内存超出最大内存时，就需要根据一定的策略去主动的淘汰一些 Key，来腾出内存，这就是内存淘汰策略。我们可以在配置文件中通过 <code>maxmemory-policy</code> 配置指定策略。</p>
<p>与到期删除策略不同，内存淘汰策略主要目的则是为了防止运行时内存超过最大内存，所以尽管最终目的都是清理内存中的一些 Key，但是它们的应用场景和触发时机是不同的。</p>
<p>算上在 4.0 添加的两种基于 LFU 算法的策略， Redis 一共提供了八种策略供我们选择：</p>
<ul>
<li><code>noeviction</code>，不淘汰任何 key，直接报错。它是默认策略。</li>
<li><code>volatile-random</code>：从所有设置了到期时间的 Key 中，随机淘汰一个 Key。</li>
<li><code>volatile-lru</code>： 从所有设置了到期时间的 Key 中，淘汰最近最少使用的 Key。</li>
<li><code>volatile-lfu</code>： 从所有设置了到期时间的 Key 中，淘汰最近最不常用使用的 Key（4.0 新增）。</li>
<li><code>volatile-ttl</code>： 从所有设置了到期时间的 Key 中，优先淘汰最早过期的 Key。</li>
<li><code>allkeys-random</code>：从所有 Key 中，随机淘汰一个键（4.0 新增）。</li>
<li><code>allkeys-lru</code>： 从所有 Key 中，淘汰最近最少使用的 Key。</li>
<li><code>allkeys-lfu</code>： 从所有 Key 中，淘汰最近最不常用使用的键。</li>
</ul>
<p>从淘汰范围来说可以分为不淘汰任何数据、只从设置了到期时间的键中淘汰和从所有键中淘汰三类。而从淘汰算法来分，又主要分为 Random（随机），LRU（最近最少使用），以及 LFU（最近最不常使用）三种。</p>
<p>其中，关于 LRU 算法，它是一种非常常见的缓存淘汰算法。我们可以简单理解为 Redis 会在每次访问 Key 的时候记录访问时间，当淘汰时，优先淘汰最后一次访问距离现在最早的 Key。</p>
<p>而对于 LFU 算法，我们可以理解为 Redis 会在访问 Key 时，根据两次访问时间的间隔计算并累加访问频率指标，当淘汰时，优先淘汰访问频率指标最低的 key。相比 LRU 算法，它避免了低频率的大批量查询造成的缓存污染问题。</p>
<p>顺带一提，只要是有类似缓存机制的应用或多或少都会面对这种问题，比如老生常谈的 MySQL 连表查询，在数据量大的时候也会造成缓存污染。</p>
<p>此外，当选择 LFU 算法时，如果数据量比较大，为了避免因为抽样数量过小导致冷热 Key 之间因为时间衰减造成的权重差异难以体现，最好将抽样大小设置的大一些，减小热数据被误伤的可能性。</p>
<h2 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h2><p>按 Key 的淘汰范围来分，我们可以把这些策略分为三类</p>
<p>1）不淘汰任何数据</p>
<p>也就是<code>noeviction</code>，它是默认的策略。</p>
<p>2）只从设置的了到期时间的 Key 中淘汰</p>
<ul>
<li><code>volatile-random</code>：从所有设置了到期时间的 Key 中，随机淘汰一个 Key。</li>
<li><code>volatile-lru</code>：从所有设置了到期时间的 Key 中，淘汰最近最少使用的 Key。</li>
<li><code>volatile-lfu</code>：从所有设置了到期时间的 Key 中，淘汰最近最不常用使用的 Key，4.0 版本新增。</li>
<li><code>volatile-ttl</code>：从所有设置了到期时间的 Key 中，优先淘汰最早过期的 Key。</li>
</ul>
<p>3）从所有的 Key 中进行淘汰</p>
<ul>
<li><code>allkeys-rando</code>：从所有 Key 中，随机淘汰一个键，4.0 版本新增。</li>
<li><code>allkeys-lru</code>：从所有 Key 中，淘汰最近最少使用的 Key。</li>
<li><code>allkeys-lfu</code>：从所有 Key 中，淘汰最近最不常用使用的键。</li>
</ul>
<h2 id="淘汰过程"><a href="#淘汰过程" class="headerlink" title="淘汰过程"></a>淘汰过程</h2><ol>
<li>每次当 Redis 执行命令时，若设置了最大内存大小 <code>maxmemory</code>，并设置了淘汰策略式，则会尝试进行一次 Key 淘汰；</li>
<li>Redis 首先会评估已使用内存（这里不包含主从复制使用的两个缓冲区占用的内存）是否大于 <code>maxmemory</code>，如果没有则直接返回，否则将计算当前需要释放多少内存，随后开始根据策略淘汰符合条件的 Key；当开始进行淘汰时，将会依次对每个数据库进行抽样，抽样的数据范围由策略决定，而样本数量则由 <code>maxmemory-samples</code>配置决定；</li>
<li>完成抽样后，Redis 会尝试将样本放入提前初始化好 <code>EvictionPoolLRU</code> 数组中，它相当于一个临时缓冲区，当数组填满以后即将里面全部的 Key 进行删除。</li>
<li>若一次删除后内存仍然不足，则再次重复上一步骤，将样本中的剩余 Key 再次填入数组中进行删除，直到释放了足够的内存，或者本次抽样的所有 Key 都被删除完毕（如果此时内存还是不足，那么就重新执行一次淘汰流程）。</li>
</ol>
<p><strong>从到期字典中抽样</strong></p>
<p>在抽样这一步，涉及到从字典中随机抽样这个过程，由于哈希表的 Key  是散列分布的，因此会有很多桶都是空的，纯随机效率可能会很低。因此，Redis  采用了一个特别的做法，那就是先连续遍历数个桶，如果都是空的，再随机调到另一个位置，再连续遍历几个桶……如此循环，直到结束抽样。</p>
<p>你可以参照源码理解这个过程：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">unsigned <span class="type">int</span> <span class="title function_">dictGetSomeKeys</span><span class="params">(dict *d, dictEntry **des, unsigned <span class="type">int</span> count)</span> &#123;</span><br><span class="line">    unsigned <span class="type">long</span> j; <span class="comment">/* internal hash table id, 0 or 1. */</span></span><br><span class="line">    unsigned <span class="type">long</span> tables; <span class="comment">/* 1 or 2 tables? */</span></span><br><span class="line">    unsigned <span class="type">long</span> <span class="variable">stored</span> <span class="operator">=</span> <span class="number">0</span>, maxsizemask;</span><br><span class="line">    unsigned <span class="type">long</span> maxsteps;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (dictSize(d) &lt; count) count = dictSize(d);</span><br><span class="line">    maxsteps = count*<span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果字典正在迁移，则协助迁移</span></span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; count; j++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (dictIsRehashing(d))</span><br><span class="line">            _dictRehashStep(d);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tables = dictIsRehashing(d) ? <span class="number">2</span> : <span class="number">1</span>;</span><br><span class="line">    maxsizemask = d-&gt;ht[<span class="number">0</span>].sizemask;</span><br><span class="line">    <span class="keyword">if</span> (tables &gt; <span class="number">1</span> &amp;&amp; maxsizemask &lt; d-&gt;ht[<span class="number">1</span>].sizemask)</span><br><span class="line">        maxsizemask = d-&gt;ht[<span class="number">1</span>].sizemask;</span><br><span class="line"></span><br><span class="line">    unsigned <span class="type">long</span> <span class="variable">i</span> <span class="operator">=</span> random() &amp; maxsizemask;</span><br><span class="line">    unsigned <span class="type">long</span> <span class="variable">emptylen</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 当已经采集到足够的样本，或者重试已达上限则结束采样</span></span><br><span class="line">    <span class="keyword">while</span>(stored &lt; count &amp;&amp; maxsteps--) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; tables; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (tables == <span class="number">2</span> &amp;&amp; j == <span class="number">0</span> &amp;&amp; i &lt; (unsigned <span class="type">long</span>) d-&gt;rehashidx) &#123;</span><br><span class="line">                <span class="keyword">if</span> (i &gt;= d-&gt;ht[<span class="number">1</span>].size)</span><br><span class="line">                    i = d-&gt;rehashidx;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 如果一个库的到期字典已经处理完毕，则处理下一个库</span></span><br><span class="line">            <span class="keyword">if</span> (i &gt;= d-&gt;ht[j].size) <span class="keyword">continue</span>;</span><br><span class="line">            dictEntry *he = d-&gt;ht[j].table[i];</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 连续遍历多个桶，如果多个桶都是空的，那么随机跳到另一个位置，然后再重复此步骤           </span></span><br><span class="line">            <span class="keyword">if</span> (he == NULL) &#123;</span><br><span class="line">                emptylen++;</span><br><span class="line">                <span class="keyword">if</span> (emptylen &gt;= <span class="number">5</span> &amp;&amp; emptylen &gt; count) &#123;</span><br><span class="line">                    i = random() &amp; maxsizemask;</span><br><span class="line">                    emptylen = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                emptylen = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">while</span> (he) &#123;</span><br><span class="line">                    *des = he;</span><br><span class="line">                    des++;</span><br><span class="line">                    he = he-&gt;next;</span><br><span class="line">                    stored++;</span><br><span class="line">                    <span class="keyword">if</span> (stored == count) <span class="keyword">return</span> stored;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 查找下一个桶</span></span><br><span class="line">        i = (i+<span class="number">1</span>) &amp; maxsizemask;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> stored;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="LRU的实现"><a href="#LRU的实现" class="headerlink" title="LRU的实现"></a>LRU的实现</h2><p>LRU 的全称为 <code>Least Recently Used</code>，也就是最近最少使用。一般来说，LRU 会从一批 Key 中淘汰上次访问时间最早的 key。</p>
<p>它是一种非常常见的缓存回收算法，在诸如 <code>Guava Cache</code>、<code>Caffeine</code>等缓存库中都提供了类似的实现。我们自己也可以基于 JDK 的 <code>LinkedHashMap</code> 实现支持 LRU 算法的缓存功能。</p>
<h3 id="近似LRU"><a href="#近似LRU" class="headerlink" title="近似LRU"></a>近似LRU</h3><p>传统的 LRU 算法实现通常会维护一个链表，当访问过某个节点后就将该节点移至链表头部。如此反复后，链表的节点就会按最近一次访问时间排序。当缓存数量到达上限后，我们直接移除尾节点，即可移除最近最少访问的缓存。</p>
<p>不过，对于 Redis 来说，如果每个 Key 添加的时候都需要额外的维护并操作这样一条链表，要额外付出的代价显然是不可接受的，因此 Redis 中的 LRU 是近似 LRU（<code>NearlyLRU</code>）。</p>
<p>当每次访问 Key 时，Redis 会在结构体中记录本次访问时间，而当需要淘汰 Key 时，将会从全部数据中进行抽样，然后再移除样本中上次访问时间最早的 key。</p>
<p>它的特点是：</p>
<ul>
<li>仅当需要时再抽样，因而不需要维护全量数据组成的链表，这避免了额外内存消耗。</li>
<li>访问时仅在结构体上记录操作时间，而不需要操作链表节点，这避免了额外的性能消耗。</li>
</ul>
<p>当然，有利就有弊，这种实现方式也决定 Redis 的 LRU 是并不是百分百准确的，被淘汰的 Key 未必真的就是所有 Key 中最后一次访问时间最早的。</p>
<p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEdeC6J"><img src="https://s21.ax1x.com/2025/03/17/pEdeC6J.png" alt="pEdeC6J.png"></a></p>
<h3 id="抽样大小"><a href="#抽样大小" class="headerlink" title="抽样大小"></a>抽样大小</h3><p>根据上述的内容，我们不难理解，当抽样的数量越大，LRU 淘汰 Key 就越准确，相对的开销也更大。因此，Redis 允许我们通过 <code>maxmemory-samples</code> 配置采样数量（默认为 5），从而在性能和精度上取得平衡。</p>
<h3 id="缓存污染"><a href="#缓存污染" class="headerlink" title="缓存污染"></a>缓存污染</h3><p>LRU 有个最大问题，就是它只认最近一次访问时间。而如果出现系统偶尔需要一次性读取大量数据的时候，会大规模更新 Key  的最近访问时间，从而导致真正需要被频繁访问的 Key 因为最近一次访问时间更早而被直接淘汰。这种情况被称为缓存污染。为此，我们需要使用 LFU  算法来解决。</p>
<h2 id="LFU算法实现"><a href="#LFU算法实现" class="headerlink" title="LFU算法实现"></a>LFU算法实现</h2><p>LFU 全称为 <code>Least Frequently Used</code> ，也就是最近最不常用。它的特点如下：</p>
<ul>
<li>同样是基于抽样实现的近似算法，<code>maxmemory-samples</code> 对其同样有效。</li>
<li>比较的不是最后一次访问时间，而是数据的访问频率。当淘汰的时候，优先淘汰范围频率最低 Key。</li>
</ul>
<p>它的实现与 LRU 基本一致，但是在计数部分则有所改进。</p>
<h3 id="概率计数器"><a href="#概率计数器" class="headerlink" title="概率计数器"></a>概率计数器</h3><p>在 Redis 用来存储数据的结构体 <code>redisObj</code> 中，有一个 24 位的 <code>lru</code>数值字段：</p>
<ul>
<li>当使用 LRU 算法时，它用于记录最后一次访问时间的时间戳。</li>
<li>当使用 LFU 算法时，它被分为两部分，高 16 位关于记录最近一次访问时间（<code>Last Decrement Time</code>），而低 8 位作为记录访问频率计数器（<code>Logistic Counter</code>）。</li>
</ul>
<p>LFU 的核心就在于低 8 位表示的访问频率计数器（下面我们简称为 <code>counter</code>），是一个介于 0 ~ 255 的特殊数值，它会每次访问 Key 时，基于时间衰减和概率递增机制动态改变。</p>
<blockquote>
<p>这种基于概率，使用极小内存对大量事件进行计数的计数器被称为莫里斯计数器，它是一种概率计数法的实现。</p>
</blockquote>
<h3 id="时间衰减"><a href="#时间衰减" class="headerlink" title="时间衰减"></a>时间衰减</h3><p>每当访问 Key  时，根据当前实际与该 Key 的最后一次访问时间的时间差对 <code>counter</code> 进行衰减。</p>
<p>衰减值取决于 <code>lfu_decay_time</code> 配置，该配置表示一个衰减周期。我们可以简单的认为，每当时间间隔满足一个衰减周期时，就会对 <code>counter</code> 减一。</p>
<p>比如，我们设置 <code>lfu_decay_time</code>为 1 分钟，那么如果 Key 最后一次访问距离现在已有 3 分 30 秒，那么 <code>counter</code> 就需要减 3。</p>
<h3 id="概率递增"><a href="#概率递增" class="headerlink" title="概率递增"></a>概率递增</h3><p>在完成衰减后，Redis 将根据 <code>lfu_log_factor</code> 配置对应概率值对 <code>counter</code> 进行递增。</p>
<p>这里直接放上源码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Logarithmically increment a counter. The greater is the current counter value</span></span><br><span class="line"><span class="comment"> * the less likely is that it gets really implemented. Saturate it at 255. */</span></span><br><span class="line">uint8_t <span class="title function_">LFULogIncr</span><span class="params">(uint8_t counter)</span> &#123;</span><br><span class="line">    <span class="comment">// 若已达最大值 255，直接返回</span></span><br><span class="line">    <span class="keyword">if</span> (counter == <span class="number">255</span>) <span class="keyword">return</span> <span class="number">255</span>;</span><br><span class="line">    <span class="comment">// 获取一个介于 0 到 1 之间的随机值</span></span><br><span class="line">    <span class="type">double</span> <span class="variable">r</span> <span class="operator">=</span> (<span class="type">double</span>)rand()/RAND_MAX;</span><br><span class="line">    <span class="comment">// 根据当前 counter 减去初始值得到 baseval</span></span><br><span class="line">    <span class="type">double</span> <span class="variable">baseval</span> <span class="operator">=</span> counter - LFU_INIT_VAL; </span><br><span class="line">    <span class="keyword">if</span> (baseval &lt; <span class="number">0</span>) baseval = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 使用 baseval*server.lfu_log_factor+1 得到一个概率值 p</span></span><br><span class="line">    <span class="type">double</span> <span class="variable">p</span> <span class="operator">=</span> <span class="number">1.0</span>/(baseval*server.lfu_log_factor+<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 当 r &lt; p 时，递增 counter</span></span><br><span class="line">    <span class="keyword">if</span> (r &lt; p) counter++;</span><br><span class="line">    <span class="keyword">return</span> counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>简而言之，直接从代码上理解，我们可以认为 <code>counter</code>和 <code>lfu_log_factor</code> 越大，则递增的概率越小</p>
<blockquote>
<p>Redis 中的 LFU（Least Frequently Used，最不经常使用）缓存淘汰策略依赖于访问频率来决定哪些键可以被优先淘汰。递增计数器（counter）的目的在于记录每个键被访问的频率，以便在需要释放内存空间时，能够根据这些数据淘汰那些相对较少被访问的键。</p>
<p>具体来说，<code>LFULogIncr</code> 函数的设计是为了实现一种基于访问次数的对数增长模式。这意味着，随着某个键被访问次数的增加，其对应的计数器递增的难度也会逐渐增大。这种机制有助于区分不同访问频率的键，即使某些键访问频率很高，它们的计数器也不会无限制地快速增加。这样做有以下几个优点：</p>
<ol>
<li><p><strong>区分活跃度</strong>：通过这种方式，Redis 可以更准确地区分出哪些键是“非常热”（即频繁访问），哪些键虽然也被访问但频率较低。</p>
</li>
<li><p><strong>防止过度淘汰</strong>：如果一个键的计数器递增过快，可能会导致它永远不会被淘汰，即使它的实际访问频率已经降低。通过对数递增的方式，可以有效避免这种情况的发生。</p>
</li>
<li><p><strong>适应不同的访问模式</strong>：不同的应用可能有不同的访问模式，通过调整 <code>lfu_log_factor</code> 参数，用户可以让 Redis 更好地适应特定的应用场景。</p>
</li>
</ol>
<p>综上所述，递增计数器是为了有效地评估和区分存储在 Redis 中的数据项的访问频率，从而为缓存淘汰策略提供依据。这种方法能够在有限的内存资源下，最大化地利用缓存空间，同时确保高访问频率的数据不容易被淘汰。</p>
</blockquote>
<h3 id="初始值"><a href="#初始值" class="headerlink" title="初始值"></a>初始值</h3><p>为了防止新的 Key 由于 <code>counter</code> 为 0 导致直接被淘汰，Redis 会默认将 <code>counter</code>设置为 5。</p>
<h3 id="抽样大小的选择"><a href="#抽样大小的选择" class="headerlink" title="抽样大小的选择"></a>抽样大小的选择</h3><p>值得注意的是，当数据量比较大的时候，如果抽样大小设置的过小，因为一次抽样的样本数量有限，冷热数据因为时间衰减导致的权重差异将会变得不明显，此时 LFU 算法的优势就难以体现，即使的相对较热的数据也有可能被频繁“误伤”。</p>
<p>所以，如果你选择了 LFU 算法作为淘汰策略，并且同时又具备比较大的数据量，那么不妨将抽样大小也设置的大一些。</p>
<h2 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h2><p>软件工程没有银弹，我们不可能指望存在一个能完美适用于所有场景的内存淘汰策略。在实际场景中，我们需要结合业务特点、数据量大小、数据的冷热……等多个维度来选择合适的淘汰策略。</p>
<p>简单的来说，如果你的业务数据的访问比较平均，不存在明显的冷热区别，那么 LRU 可以满足一般的使用需求。如果你的业务具备很强的时效性，而且是存在大促商品这种明显的热点数据，那么推荐你使用 LFU。</p>
<p>当然，思路要打开，调整淘汰策略只是优化方案的一种，条件允许的话，在特定情况下直接增加内存、将单机改为集群或者缓存预热同样可以带来显著的收益。</p>
<h1 id="Redis是不是CPU核数越高越好？"><a href="#Redis是不是CPU核数越高越好？" class="headerlink" title="Redis是不是CPU核数越高越好？"></a>Redis是不是CPU核数越高越好？</h1><p>Redis 是单线程的，这意味着在任何给定时刻只能处理一个请求。</p>
<p>因此，它更侧重于单个核心的性能，而不是多核心。高速缓存访问和处理请求的速度可能会受到 CPU 速度的限制，而不是核心数。</p>
<p>当然，不能真的为 Redis 只分配 1 个核心，因为 Redis 除了主线程处理从客户端发起的读写请求外，还会有一些异步的处理，比如：持久化操作、主从复制等，所以推荐设置 2 核 CPU 即可。</p>
<p>我看了腾讯云 Redis 默认会为每个节点分配 2 核 CPU，1 个 CPU 负责主线程处理读写请求，另外 1 个 CPU 用于处理后台任务。</p>
<h1 id="如何提升Redis批量访问性能？"><a href="#如何提升Redis批量访问性能？" class="headerlink" title="如何提升Redis批量访问性能？"></a>如何提升Redis批量访问性能？</h1><p>可以从两个方面提高，一个是从 API 操作命令上优化，另一个则是通过聚合批命令节省网络 IO。</p>
<h2 id="批量命令"><a href="#批量命令" class="headerlink" title="批量命令"></a>批量命令</h2><p>以 Redis Hash 结构举例，涉及到批量操作，Redis 提供了 <code>MGET</code> 和 <code>MSET</code> 命令，可以一次性获取多个键的值或者设置多个键的值。</p>
<h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>使用 <code>Pipeline</code> 可以在一次网络往返中发送多个命令，从而减少了通信开销。通过将多个命令打包发送，可以极大地提升批量访问的性能。使用上需要注意：<code>Pipeline</code> 并不会保证原子性，所以在涉及事务和多个命令的情况下，需要格外小心。</p>
<p>Redis Pipeline（管道）是一种可以在一次网络往返中发送多个命令并接收它们的响应的机制。这样可以减少网络通信的开销，从而提升了 Redis 的批量操作性能。</p>
<p>在普通模式下，每个 Redis 命令都会在客户端发送给 Redis 服务器后，等待 Redis 服务器的响应，然后再发送下一个命令。</p>
<p>当使用 Pipeline 时，客户端可以一次性发送多个命令给 Redis 服务器，而无需等待每个命令的响应。这意味着一次网络往返可以执行多个命令。</p>
<ol>
<li>客户端会将多个命令打包发送到 Redis 服务器，这些命令会被按照发送的顺序执行。</li>
<li>Redis 服务器会依次处理接收到的命令，并将它们按照顺序执行。</li>
<li>一旦所有命令被执行完毕，Redis 服务器会将它们的响应一次性发送给客户端。</li>
<li>客户端会按照发送命令的顺序依次接收到各个命令的响应。这些响应可以被客户端用来处理相应的结果。</li>
</ol>
<p>Pipeline 管道命令注意事项：</p>
<ul>
<li>Pipeline 过大可能会导致网络拥堵：如果一次性发送的命令过多，可能会导致网络拥塞，反而降低性能。</li>
<li>Pipeline 并不保证原子性：如果在 Pipeline 中的某个命令执行失败，它不会回滚已经执行的命令。</li>
<li>适用场景：Pipeline 适合于批量读取或写入大量的数据，特别是在需要频繁地与 Redis 进行交互时。</li>
</ul>
<h2 id="LUA脚本"><a href="#LUA脚本" class="headerlink" title="LUA脚本"></a>LUA脚本</h2><p>如果需要保证原子性的同时还需要批量特性，可以使用 Lua 脚本在 Redis 机器上原子地执行多个命令序列。这对于需要在多个键之间执行复杂操作的情况非常有用。</p>
<p>Redis 的 Lua 脚本功能允许你在 Redis 服务器上执行自定义的脚本。这些脚本可以实现复杂的逻辑操作，同时保证了在执行期间的原子性。</p>
<p>执行流程如下：</p>
<ol>
<li>Redis 会将脚本作为一个单独的原子操作来执行。这意味着在脚本执行期间，其他客户端的请求不会被插入，保证了脚本的原子性。</li>
<li>脚本可以接收键和参数作为输入，并可以返回一个或多个值作为输出。</li>
<li>脚本执行完毕后，Redis 会将脚本的返回值发送给客户端。</li>
</ol>
<p>在 Redis 中，可以使用 <code>EVAL</code> 命令来执行 Lua 脚本。<code>EVAL</code> 命令接受脚本字符串、键的数量和具体的键名作为参数。</p>
<p>需要注意的是，Lua 脚本是在 Redis 服务器上原子执行的，但是在编写脚本时，需要确保脚本的执行时间不会过长，以免影响其他客户端的请求。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Allimac</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/03/22/Redis-hot-issues/">http://example.com/2025/03/22/Redis-hot-issues/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">AllimacBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%85%AB%E8%82%A1/">八股</a><a class="post-meta__tags" href="/tags/Redis/">Redis</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/03/15/Push-Pull-ModeInMQ/" title="Push-Pull-ModeInMQ"><img class="cover" src="https://s21.ax1x.com/2025/03/15/pEaaqMR.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Push-Pull-ModeInMQ</div></div><div class="info-2"><div class="info-item-1">消息队列当中的推拉模式</div></div></div></a><a class="pagination-related" href="/2025/03/22/Redis-High-Availability-architecture/" title="Redis-High-Availability-architecture"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Redis-High-Availability-architecture</div></div><div class="info-2"><div class="info-item-1">高可用架构实现</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/03/22/RedisDS/" title="RedisDS"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-22</div><div class="info-item-2">RedisDS</div></div><div class="info-2"><div class="info-item-1">Redis相关的数据结构</div></div></div></a><a class="pagination-related" href="/2025/03/22/Redis-High-Availability-architecture/" title="Redis-High-Availability-architecture"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-22</div><div class="info-item-2">Redis-High-Availability-architecture</div></div><div class="info-2"><div class="info-item-1">高可用架构实现</div></div></div></a><a class="pagination-related" href="/2025/03/15/A-First-Look-At-Kafka/" title="A-First-Look-At-Kafka"><img class="cover" src="https://s21.ax1x.com/2025/03/15/pEaUHDP.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-15</div><div class="info-item-2">A-First-Look-At-Kafka</div></div><div class="info-2"><div class="info-item-1">初探Kafka，一些关于Kafka的问题</div></div></div></a><a class="pagination-related" href="/2025/03/15/A-First-Look-At-RocketMQ/" title="A-First-Look-At-RocketMQ"><img class="cover" src="https://s21.ax1x.com/2025/03/15/pEaULE8.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-15</div><div class="info-item-2">A-First-Look-At-RocketMQ</div></div><div class="info-2"><div class="info-item-1">初探RocketMQ，一些关于RocketMQ的问题</div></div></div></a><a class="pagination-related" href="/2025/03/15/A-First-Look-At-Zookeeper/" title="A-First-Look-At-Zookeeper"><img class="cover" src="https://s21.ax1x.com/2025/03/15/pEaaHz9.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-15</div><div class="info-item-2">A-First-Look-At-Zookeeper</div></div><div class="info-2"><div class="info-item-1">初探Zookeeper，一些关于Zookeeper的问题</div></div></div></a><a class="pagination-related" href="/2025/03/22/BloomFilter/" title="BloomFilter"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-22</div><div class="info-item-2">BloomFilter</div></div><div class="info-2"><div class="info-item-1">布隆过滤器入门</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Allimac</div><div class="author-info-description">华丽的仓库存放着我简陋的思想</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">49</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">44</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/AillemaCc"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/AillemaCc" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="http://www.swindle.icu/#/Home" target="_blank" title="曾经的博客"><i class="fas fa-envelope" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这里是小梦一场的大床</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB"><span class="toc-number">1.</span> <span class="toc-text">Redis为什么这么快</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AD%98%E6%93%8D%E4%BD%9C"><span class="toc-number">1.1.</span> <span class="toc-text">基于内存操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%88%E7%90%86%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">合理的线程模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%95%88IO%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.</span> <span class="toc-text">高效IO模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"><span class="toc-number">1.3.1.</span> <span class="toc-text">IO多路复用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%9D%9E%E9%98%BB%E5%A1%9EIO"><span class="toc-number">1.3.2.</span> <span class="toc-text">多线程非阻塞IO</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.4.</span> <span class="toc-text">数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2"><span class="toc-number">1.4.1.</span> <span class="toc-text">简单动态字符串</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%97%E5%85%B8-%E5%93%88%E5%B8%8C%E8%A1%A8"><span class="toc-number">1.4.2.</span> <span class="toc-text">字典&#x2F;哈希表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%B3%E8%A1%A8"><span class="toc-number">1.4.3.</span> <span class="toc-text">跳表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%B0%E6%9C%9F%E5%88%A0%E9%99%A4"><span class="toc-number">2.</span> <span class="toc-text">如何实现到期删除</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%B0%E6%9C%9F%E6%97%B6%E9%97%B4"><span class="toc-number">2.1.</span> <span class="toc-text">到期时间</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5"><span class="toc-number">2.2.</span> <span class="toc-text">删除策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E6%97%B6%E5%88%A0%E9%99%A4"><span class="toc-number">2.2.1.</span> <span class="toc-text">定时删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%83%B0%E6%80%A7%E5%88%A0%E9%99%A4"><span class="toc-number">2.2.2.</span> <span class="toc-text">惰性删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4"><span class="toc-number">2.2.3.</span> <span class="toc-text">定期删除</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%8A%BD%E6%A0%B7%E8%80%8C%E4%B8%8D%E6%98%AF%E5%85%A8%E9%87%8F%E6%A3%80%E6%9F%A5"><span class="toc-number">2.2.3.1.</span> <span class="toc-text">为什么要抽样而不是全量检查</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%AE%9A%E6%9C%9F%E5%88%A0%E9%99%A4%E7%9A%84%E8%A7%A6%E5%8F%91%E9%A2%91%E7%8E%87"><span class="toc-number">2.2.3.2.</span> <span class="toc-text">如何控制定期删除的触发频率</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E6%8C%81%E4%B9%85%E5%8C%96%E6%97%B6"><span class="toc-number">2.3.</span> <span class="toc-text">在持久化时</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E9%9B%86%E7%BE%A4%E4%B8%AD"><span class="toc-number">2.4.</span> <span class="toc-text">在集群中</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5"><span class="toc-number">3.</span> <span class="toc-text">内存淘汰策略</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5"><span class="toc-number">3.1.</span> <span class="toc-text">淘汰策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%98%E6%B1%B0%E8%BF%87%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">淘汰过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LRU%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">LRU的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%91%E4%BC%BCLRU"><span class="toc-number">3.3.1.</span> <span class="toc-text">近似LRU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%BD%E6%A0%B7%E5%A4%A7%E5%B0%8F"><span class="toc-number">3.3.2.</span> <span class="toc-text">抽样大小</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93"><span class="toc-number">3.3.3.</span> <span class="toc-text">缓存污染</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LFU%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.4.</span> <span class="toc-text">LFU算法实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E8%AE%A1%E6%95%B0%E5%99%A8"><span class="toc-number">3.4.1.</span> <span class="toc-text">概率计数器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E8%A1%B0%E5%87%8F"><span class="toc-number">3.4.2.</span> <span class="toc-text">时间衰减</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E9%80%92%E5%A2%9E"><span class="toc-number">3.4.3.</span> <span class="toc-text">概率递增</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%80%BC"><span class="toc-number">3.4.4.</span> <span class="toc-text">初始值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%BD%E6%A0%B7%E5%A4%A7%E5%B0%8F%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">3.4.5.</span> <span class="toc-text">抽样大小的选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9"><span class="toc-number">3.5.</span> <span class="toc-text">如何选择</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E6%98%AF%E4%B8%8D%E6%98%AFCPU%E6%A0%B8%E6%95%B0%E8%B6%8A%E9%AB%98%E8%B6%8A%E5%A5%BD%EF%BC%9F"><span class="toc-number">4.</span> <span class="toc-text">Redis是不是CPU核数越高越好？</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87Redis%E6%89%B9%E9%87%8F%E8%AE%BF%E9%97%AE%E6%80%A7%E8%83%BD%EF%BC%9F"><span class="toc-number">5.</span> <span class="toc-text">如何提升Redis批量访问性能？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E5%91%BD%E4%BB%A4"><span class="toc-number">5.1.</span> <span class="toc-text">批量命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%A1%E9%81%93"><span class="toc-number">5.2.</span> <span class="toc-text">管道</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LUA%E8%84%9A%E6%9C%AC"><span class="toc-number">5.3.</span> <span class="toc-text">LUA脚本</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/26/Compinent-Library-12306/" title="Compinent-Library-12306">Compinent-Library-12306</a><time datetime="2025-03-26T03:39:58.000Z" title="发表于 2025-03-26 11:39:58">2025-03-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/22/BloomFilter/" title="BloomFilter">BloomFilter</a><time datetime="2025-03-22T10:26:57.000Z" title="发表于 2025-03-22 18:26:57">2025-03-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/22/RedisDS/" title="RedisDS">RedisDS</a><time datetime="2025-03-22T10:23:33.000Z" title="发表于 2025-03-22 18:23:33">2025-03-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/22/Redis-High-Availability-architecture/" title="Redis-High-Availability-architecture">Redis-High-Availability-architecture</a><time datetime="2025-03-22T10:22:31.000Z" title="发表于 2025-03-22 18:22:31">2025-03-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/22/Redis-hot-issues/" title="Redis-hot-issues">Redis-hot-issues</a><time datetime="2025-03-22T10:19:32.000Z" title="发表于 2025-03-22 18:19:32">2025-03-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By Allimac</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>